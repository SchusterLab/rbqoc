\section{Background \label{sec:background}}
In this section, we
review the QOC problem statement
and describe the ALTRO solver \cite{howell2019altro}.
QOC concerns a vector $\mathbf{a}(t)$ of time-dependent control fields
that steer the evolution of a quantum state $\ket{\psi(t)}$.
The evolution of the state is governed by the time-dependent
Schr{\"o}dinger equation (TDSE),
\begin{equation}
  i \hbar \frac{d}{dt} \ket{\psi(t)} = H(\mathbf{a}(t), t) \ket{\psi(t)}.
  \label{eq:tdse}
\end{equation}
The Hamiltonian $H(\mathbf{a}(t), t)$ is determined by the quantum system and the external control fields.
The QOC problem is to find the
controls that minimize a functional $J[\mathbf{a}(t)]$,
which we call the objective.
To make the problem numerically tractable,
the quantum state and controls are discretized into $N$ time steps,
$\ket{\psi(t_{k})} \to \ket{\psi_k}$ and $\mathbf{a}(t_{k}) \to \mathbf{a}_k$ where
$t_{k} = t_{k - 1} + \Delta t$ and $k \in \{1, ..., N\}$.
In the case of a single state-transfer problem, the objective is
the infidelity of the time-evolved final state $\ket{\psi_N}$ and
the intended target state $\ket{\psi_T}$,
$J(\mathbf{a}) = 1 - {\lvert \braket{\psi_{T}}{\psi_{N}(\mathbf{a})} \rvert}^{2}$.
Standard QOC solvers compute derivatives of the objective $\nabla J(\mathbf{a})$,
which can easily be used to implement first-order optimization methods
\cite{machnes2015tunable, khaneja2005optimal, leung2017speedup, goerz2019krotov}.

Alternatively, the QOC problem can be formulated as a trajectory optimization problem 
and solved using specialized solvers developed by the robotics community
\cite{Schulman13, Tedrake16, Hereid2017FROST, howell2019altro}.
The objective $J(\mathbf{a})=\sum_k \ell_{k}(\mathbf{x}_{k}, \mathbf{u}_{k})$
is expressed in terms of the
cost function at each time step $\ell_k$, where
$\mathbf{x}_{k}$ is the augmented state vector
and $\mathbf{u}_{k}$ is the augmented control vector.
We use the term \emph{augmented} because these
vectors contain all of the relevant variables in the optimization problem,
not just the quantum state and the control fields,
for an example see Sec. \ref{sec:fluxonium}.
The augmented control contains all variables that the experimentalist
may manipulate, and the augmented state contains all variables that depend
on those in the augmented control.
The variables in the augmented states depend on those in the augmented
controls as defined by the differential equations governing the physical system, which are
encoded in the discrete relation
$\mathbf{x}_{k + 1} = \mathbf{f}(\mathbf{x}_{k}, \mathbf{u}_{k})$.
For QOC, $\mathbf{f}(\mathbf{x}_{k}, \mathbf{u}_{k})$ -- which we call
the discrete dynamics function -- propagates the quantum state by
integrating the TDSE \eqref{eq:tdse}
using a Runge-Kutta method \cite{jorgensen2011numerical}
or an exponential integrator \cite{auer2018magnus, berland2006solving, einkemmer2017performance,
  shillito2020fast}.

We incorporate constraints on the augmented controls and states
by formulating them as inequalities  $\mathbf{g}_{k}(\mathbf{x}_{k}, \mathbf{u}_{k}) \leq \mathbf{0}$
or equalities $\mathbf{h}_{k}(\mathbf{x}_{k}, \mathbf{u}_{k}) = \mathbf{0}$.
The constraint functions $\mathbf{g}_k$ and $\mathbf{h}_k$ may be vector-valued to encode multiple constraints,
and equalities and inequalities are understood component-wise.
To quantify constraint satisfaction, we define each constraint's \emph{violation}
as the magnitude of its deviation:
$\textrm{max}(g(\cdot), 0)$ or $\abs{h(\cdot)}$, where $g$ and $h$
are components of constraint functions $\mathbf{g}_{k}$ and $\mathbf{h}_{k}$,
respectively.
Stated concisely, the trajectory optimization problem is:
\begin{mini!}[2]
  {\substack{\mathbf{x}_1, \ldots, \mathbf{x}_N \\\mathbf{u}_1, \ldots, \mathbf{u}_{N - 1}}}{
    \sum^{N}_{k = 1}\ell_{k}
    (\mathbf{x}_k,\mathbf{u}_k),}{}{} \label{eq:gcostfun}
  \addConstraint{\mathbf{x}_{k+1} = \mathbf{f}(\mathbf{x}_k,\mathbf{u}_k) \ \forall \ k}
  \label{eq:gdyncon}
  \addConstraint{\mathbf{g}_k(\mathbf{x}_k,\mathbf{u}_k) \leq \mathbf{0} \ \forall \ k}
  \label{eq:ineqcon}
  \addConstraint{\mathbf{h}_k(\mathbf{x}_k,\mathbf{u}_k) = \mathbf{0} \ \forall \ k.}
  \label{eq:eqcon}
\end{mini!}
We have formulated the problem such that the cost and constraint functions at
time step $k$ may only depend on the augmented control and state at time step $k$.
Although this structure may appear limiting, the problem can
typically be reformulated to accomodate any cost or constraint function,
for an example see Sec. \ref{sec:fluxonium}, and the ALTRO solver,
which we introduce in the following discussion, exploits this
structure to efficiently solve the problem.

Standard techniques for solving \eqref{eq:gcostfun}-\eqref{eq:eqcon} typically
fall into two categories: direct methods \cite{Hargraves87, kelly2017introduction}
and indirect methods \cite{betts1998survey}. For indirect methods,
the augmented controls are the \emph{decision variables}, i.e., the
variables the optimizer adjusts to solve the problem.
The augmented states are obtained from the augmented controls using the discrete dynamics function,
and they are used to evaluate derivatives of the cost functions.
Then, the derivative information is employed to update the augmented controls.
This approach is taken by standard QOC solvers such as GOAT \cite{machnes2015tunable},
GRAPE \cite{khaneja2005optimal, leung2017speedup}, and Krotov's method \cite{goerz2019krotov}.
Conversely, direct methods treat both the augmented controls and states as decision
variables. In addition to minimizing the cost functions, the optimizer uses derivative information
for the discrete dynamics function to satisfy the dynamics constraint
\eqref{eq:gdyncon} to a specified tolerance.
In this sense, the TDSE \eqref{eq:tdse} is a constraint that may be violated
for intermediate steps of the optimization, where the quantum states need not be physical.
The direct approach lends itself to a nonlinear program formulation, for which
a variety of general-purpose solvers exist \cite{gill2005snopt, wachter2006implementation}.

Recent state-of-the-art solvers, such as ALTRO,
combine the indirect and direct methods in a two-stage approach.
First, ALTRO employs an indirect solving stage using
the iterative linear-quadratic regulator (iLQR) algorithm
\cite{Li2004a} as the internal solver of an augmented Lagrangian method (ALM)
\cite{lantoine2012hybrid, plancher2017constrained, nocedal2006numerical}.
In the second direct stage, ALTRO uses a projected Newton method
\cite{bertsekas1982projected, rao1998application}.
Next, we provide a more detailed summary of these two stages.

iLQR is an indirect method
for minimizing the objective subject to the dynamics constraint,
i.e., solving \eqref{eq:gcostfun}-\eqref{eq:gdyncon}.
First, iLQR uses an initial guess for the augmented controls to obtain the 
augmented states with the discrete dynamics function.
iLQR then constructs quadratic models for each cost function using
their zeroth-, first- and second-order derivatives in a Taylor expansion
about the current augmented controls and states.
These models are used with a recurrence relation between time steps
to obtain the locally optimal update for the augmented controls.
This recurrence relation is possible to derive in closed
form because cost function contributions come only from the augmented
control and state at a single time step \cite{mayne1966a}.
Finally, a line search \cite{zhang2006global}
is performed in the direction of the locally optimal update to ensure a
decrease in the objective.
This procedure is repeated until convergence is reached.

While indirect solvers like iLQR are computationally
efficient and maintain high accuracy for the discrete dynamics
throughout the optimization, they cannot handle
nonlinear equality and inequality
constraints \eqref{eq:ineqcon}-\eqref{eq:eqcon}.
For QOC, a popular approach to handle such constraints
is to add the constraint functions to the objective
\cite{heeres2017implementing, leung2017speedup, reinhold2019controlling, niu2019universal}.
However, this strategy does not guarantee that the constraints
are satisfied as the solver trades
minimization of the cost functions and constraint functions against each other.
ALM remedies this issue by adaptively adjusting a Lagrange multiplier estimate
for each constraint function to ensure the constraints are satisfied.
ALM adds terms that are linear and quadratic in the constraint functions
to the objective. Then, the new objective is minimized with
iLQR. If the solution obtained with iLQR does not satisfy the constraints,
the prefactors for the constraint terms in the objective are increased
intelligently and the procedure is repeated.

ALM converges superlinearly, but poor numerical conditioning may lead
to small decreases in the constraint violations near the locally optimal solution
\cite{bertsekas2014constrained}.
To address this shortcoming, ALTRO
projects the solution from the ALM stage onto the constraint manifold using
a (direct) projected Newton method, achieving ultra-low
constraint violations $\sim 10^{-8}$.
For more information on the details of the ALTRO
solver, see Refs. \cite{howell2019altro, Jackson2020altroc}.

As opposed to standard QOC solvers, ALTRO
can satisfy constraints on both the control fields and quantum states to tight tolerances.
This advantage is crucial for this work, where multiple medium-priority cost functions
are minimized subject to many high-priority constraints.

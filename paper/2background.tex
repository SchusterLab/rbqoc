\section{QOC + ALTRO \label{sec:background}}
In this section we
review the quantum optimal control problem statement
and introduce the ALTRO solver.
Quantum optimal control concerns the evolution of
a quantum state $\ket{\psi(t)}$ governed by the time-dependent
Schr{\"o}dinger equation (TDSE),
\begin{equation}
  i \hbar \frac{d}{dt} \ket{\psi(t)} = H(u(t), t) \ket{\psi(t)}
  \label{eq:tdse}
\end{equation}
The Hamiltonian has an arbitrary dependence on the possibly multi-valued controls $u(t)$.
The controls are so called because they are the means the experimentalist has to
act on the system. To make the problem numerically tractable,
the controls and quantum state are discretized into $N$ knot points (time steps).
The optimization problem is to find the
controls that minimize a functional $J(u)$.
In the simplest case the functional is
the infidelity between the inital state evolved
to the final knot point and the target state
$J = 1 - {\lvert \braket{\psi_{f}}{\psi_{N}(u)} \rvert}^{2}$.
In general, $J$ is a linear combinaion of cost functions on the state
as well as cost functions on the controls \cite{leung2017speedup}.
Typical quantum optimal control
algorithms employ automatic differentiation
to compute gradients of the functional $\nabla_{u} J(u)$,
which can easily be used to implement first-order optimization methods
\cite{machnes2015gradient, khaneja2005optimal, leung2017speedup, goerz2019krotov}.

Alternatively, the QOC problem can be formulated as a trajectory optimization problem 
and solved using a variety of specialized solvers developed by the robotics community
\cite{Schulman13,Tedrake16,Hereid2017FROST,howell2019altro}.
Trajectory optimization problems are typically of the following form: 
\begin{mini}[2]
    {x_{0:N},u_{0:N-1}}{\ell_f(x_N) + \sum_{k=1}^{N-1} \ell(x_k,u_k) }{}{}
    \addConstraint{x_{k+1} = f(x_k,u_k)}
    \addConstraint{g_k(x_k,u_k)}{\leq 0}
    \addConstraint{h_k(x_k,u_k)}{=0}
    \label{opt:discrete_trajopt},
\end{mini}
where $\ell_f$ and $\ell$ are the final and stage cost functions, $x_k \in \R^n$ and
$u_k \in \R^m$ are the augmented state and input augmented control variables,
$f(x_k,u_k)$ is the discrete dynamics function, and $g_k(x_k,u_k)$ and
$h_k(x_k,u_k)$ are the inequality
and equality constraints, potentially including initial and final conditions,
at time step $k$.

Many techniques have been proposed for solving \eqref{opt:discrete_trajopt}. Standard 
methods include direction collocation \cite{Hargraves87} and differential-dynamic programming
(DDP) \cite{Mayne1966a}. Recent state-of-the-art solvers, such as ALTRO \cite{howell2019altro},
have combined principles from both of these approaches.

ALTRO uses iterative LQR (iLQR) \cite{Li2004a} as the internal solver of an augmented 
Lagrangian method (ALM). iLQR solves an unconstrained trajectory optimization problem 
using a backward Riccati recursion to derive a closed-loop linear feedback law about the current 
trajectory. By simulating the system forward with the feedback law, the trajectory is 
brought closer to the (locally) optimal trajectory. DDP-based solvers such as iLQR
are popular since they are very computationally efficient, are always dynamically feasible,
and provide a locally stabilizing closed-loop control policy about the optimal trajectory. However,
standard implementations have no ability to deal with nonlinear equality and inequality 
constraints. ALM handles constraints by successively solving unconstrained minimization 
problems of the form:
\begin{mini}[2]
    {z}{f(z) + \lambda^T c(z) + \half c(z)^T I_\mu c(z)}{}{}
    \label{opt:alm}
\end{mini}
where $f(z)$ is the objective function, $c(z) : \R^n \mapsto \R^p$ is the constraint 
function, $\lambda \in \R^p$ is a Lagrange multiplier estimate, and $I_\mu$ is a diagonal matrix
of penalty weights, $\mu$, whose magnitudes depend on whether the corresponding constraint is active or inactive.
For ALTRO, $f(z)$ is the objective function of \eqref{opt:discrete_trajopt}, $c(z)$ is the 
concatenation of $g_k$ and $h_k$, and $z$ is the concatenation of the states and controls 
across all time steps. After minimizing \eqref{opt:alm} using iLQR,
the Lagrange multiplier estimates are updated according to,
\begin{equation}
	\lambda \gets \lambda + \mu c(z) ,
\end{equation}
the penalty terms are updated, and the process repeats until convergence.

ALM converges superlinearly but tends to exhibit slow constraint convergence near the optimal 
solution due to poor numerical conditioning. To address this shortcoming, ALTRO provides a 
solution-polishing phase that takes 1-2 Newton steps on the active constraint set to provide 
machine-precision constraint satisfaction. For more information on the details of the ALTRO
solver, see \cite{howell2019altro, Jackson2020altroc}.

As opposed to standard QOC solvers, the ALTRO solver provides a unified framework
for imposing arbitrary, simultaneous constraints
on both the state trajectory and the controls and does not restrict
optimization to the constraint manifold. First-order solvers like GRAPE
rely on unconstrained optimization to satisfy desiderata on the state trajectory,
such as achieving a desired gate fidelity, forbidding occupations of particular quantum states,
and smoothing the controls below a threshold. The unconstrained approach relies
on a careful choice of competing penalty weights, which is cumbersome and often intractable.
To impose constraints on the controls, such as amplitude restrictions, first-order solvers
employ projected gradient descent methods which restrict optimization to the constraint manifold and
may hinder convergence to the optimal solution \cite{clarkson2010coresets,
  hauswirth2016projected}.
The ALTRO solver delays projecting onto the constraint manifold until the ALM
solve is already at a coarse tolerance, achieving machine-precision satisfaction
for constraints on the controls and the state trajectory. These advantage are critical
for this work, where multiple constraints must be satisfied in addition
to minimizing auxiliary metrics.


